{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd #Dataframe, Series\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import graphviz\n",
    "import pydotplus\n",
    "import io\n",
    "\n",
    "from scipy import misc\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy.util as util\n",
    "\n",
    "cid =\"c8c47267a0d14b7cbb529001dd126978\" \n",
    "secret = \"41d0284be0d24f5aa9e5b7a6ff3fc039\"\n",
    "username = \"12156070492\"\n",
    "redirect_uri = \"http://localhost:8888/\"\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "#for avaliable scopes see https://developer.spotify.com/web-api/using-scopes/\n",
    "scope = 'user-library-read playlist-modify-public playlist-modify-private playlist-read-private'\n",
    "\n",
    "token = util.prompt_for_user_token(username, scope, cid, secret, redirect_uri)\n",
    "if token:\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "else:\n",
    "    print(\"Can't get token for\", username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data to the Model\n",
    "- You need to include the user you want to get the playlist from as well as the playlist id's of your good and bad playlists.\n",
    "- To do this go to your good and bad playlists and copy the links.\n",
    "    - An example spotify link: https://open.spotify.com/user/1287242681/playlist/5OdH7PmotfAO7qDGxKdw3J\n",
    "    - The user is the number after user/ and the playlist id is after the playlist/.\n",
    "\n",
    "- The method signature is sp.user_playlist('user', 'playlist_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorials\n",
    "# good_playlist = sp.user_playlist(\"1287242681\", \"5OdH7PmotfAO7qDGxKdw3J\")\n",
    "# bad_playlist = sp.user_playlist(\"1287242681\", \"3ySDAXYGUwRrp8C4ejIm9m\")\n",
    "\n",
    "# Megan's\n",
    "# good_playlist = sp.user_playlist(\"oa66aggjdka7torff2helltk6\", \"1rArXwbIyQvU31gzc5XHHY?si=6oQTTUWTQ4-xizaDju06ug\")\n",
    "# bad_playlist = sp.user_playlist(\"oa66aggjdka7torff2helltk6\", \"13bLJeS4U2Drj8SCcwAH24?si=1-aMqHL4ST69DJL1Ho6ZwA\")\n",
    "\n",
    "# My Playlists\n",
    "good_playlist = sp.user_playlist(\"12156070492\", \"1CEtpLF6xMXR4ODsMBNjhv\")\n",
    "bad_playlist = sp.user_playlist(\"12156070492\", \"0dgHltQuMc4vsRw76U9C1N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the good song id's out of the good playlists, need it for the audio features call.\n",
    "good_tracks = good_playlist[\"tracks\"]\n",
    "good_songs = good_tracks[\"items\"] \n",
    "while good_tracks['next']:\n",
    "    good_tracks = sp.next(good_tracks)\n",
    "    for item in good_tracks[\"items\"]:\n",
    "        good_songs.append(item)\n",
    "good_ids = [] \n",
    "print(len(good_songs))\n",
    "for i in range(len(good_songs)- 500):\n",
    "    good_ids.append(good_songs[i]['track']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1665\n"
     ]
    }
   ],
   "source": [
    "#Now do the same thing for the bad playlist\n",
    "bad_tracks = bad_playlist[\"tracks\"]\n",
    "bad_songs = bad_tracks[\"items\"] \n",
    "while bad_tracks['next']:\n",
    "    bad_tracks = sp.next(bad_tracks)\n",
    "    for item in bad_tracks[\"items\"]:\n",
    "        bad_songs.append(item)\n",
    "bad_ids = [] \n",
    "print(len(bad_songs))\n",
    "for i in range(len(bad_songs)):\n",
    "    bad_ids.append(bad_songs[i]['track']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-022cbfc9301e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0maudio_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrack\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/spotipy/client.py\u001b[0m in \u001b[0;36maudio_features\u001b[0;34m(self, tracks)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'audio-features/?ids='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrackid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0mtlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'audio-features/?ids='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;31m# the response has changed, look for the new style first, and if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/spotipy/client.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'audio-features/?ids='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrackid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0mtlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'audio-features/?ids='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;31m# the response has changed, look for the new style first, and if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/spotipy/client.py\u001b[0m in \u001b[0;36m_get_id\u001b[0;34m(self, type, id)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "#Here is where we get all of the audio_features for the tracks on the good and bad playlists.\n",
    "features = []\n",
    "inSavedTracks = []\n",
    "j = 0\n",
    "for i in range(0,len(good_ids),50):\n",
    "    audio_features = sp.audio_features(good_ids[i:i+50])\n",
    "    for track in audio_features:\n",
    "        features.append(track)\n",
    "        track = good_songs[j]\n",
    "        j= j+1\n",
    "        features[-1]['trackPopularity'] = track['track']['popularity']\n",
    "        features[-1]['artistPopularity'] = sp.artist(track['track']['artists'][0]['id'])['popularity']\n",
    "        features[-1]['target'] = 1\n",
    "j = 0\n",
    "for i in range(0,len(bad_ids),50):\n",
    "    audio_features = sp.audio_features(bad_ids[i:i+50])\n",
    "    for track in audio_features:\n",
    "        features.append(track)\n",
    "        track = good_songs[j]\n",
    "        j= j+1\n",
    "        features[-1]['trackPopularity'] = track['track']['popularity']\n",
    "        features[-1]['artistPopularity'] = sp.artist(track['track']['artists'][0]['id'])['popularity']\n",
    "        features[-1]['target'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Data Modeling\n",
    "- Now that we have the data on what songs you like and don't like let's visualize some of that info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingData = pd.DataFrame(features)\n",
    "# trainingData.head()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models using my own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features)\n",
    "filename = 'arcy_music.csv'\n",
    "df.to_csv(filename, index=False, encoding='utf-8')\n",
    "trainingData = pd.read_csv(\"arcy_music.csv\")\n",
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In training this classifier, we need so split our data into training and testing data so our classifier has things to train on and then test if it is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(trainingData, test_size = 0.20)\n",
    "print(\"Training size: {}, Test size: {}\".format(len(train),len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Color Palette for graphs\n",
    "red_blue = ['#19B5FE', '#EF4836']\n",
    "palette = sns.color_palette(red_blue)\n",
    "sns.set_palette(palette)\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) First, break out all of the data into positive and negative categories for all the features we want to compare\n",
    "\n",
    "Also, I know there has to be a better way of doing this, but copy paste is my friend. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tempo = trainingData[trainingData['target'] == 1]['tempo']\n",
    "neg_tempo = trainingData[trainingData['target'] == 0]['tempo']\n",
    "pos_dance = trainingData[trainingData['target'] == 1]['danceability']\n",
    "neg_dance = trainingData[trainingData['target'] == 0]['danceability']\n",
    "pos_duration = trainingData[trainingData['target'] == 1]['duration_ms']\n",
    "neg_duration = trainingData[trainingData['target'] == 0]['duration_ms']\n",
    "pos_loudness = trainingData[trainingData['target'] == 1]['loudness']\n",
    "neg_loudness = trainingData[trainingData['target'] == 0]['loudness']\n",
    "pos_speechiness = trainingData[trainingData['target'] == 1]['speechiness']\n",
    "neg_speechiness = trainingData[trainingData['target'] == 0]['speechiness']\n",
    "pos_valence = trainingData[trainingData['target'] == 1]['valence']\n",
    "neg_valence = trainingData[trainingData['target'] == 0]['valence']\n",
    "pos_energy = trainingData[trainingData['target'] == 1]['energy']\n",
    "neg_energy = trainingData[trainingData['target'] == 0]['energy']\n",
    "pos_acousticness = trainingData[trainingData['target'] == 1]['acousticness']\n",
    "neg_acousticness = trainingData[trainingData['target'] == 0]['acousticness']\n",
    "pos_key = trainingData[trainingData['target'] == 1]['key']\n",
    "neg_key = trainingData[trainingData['target'] == 0]['key']\n",
    "pos_instrumentalness = trainingData[trainingData['target'] == 1]['instrumentalness']\n",
    "neg_instrumentalness = trainingData[trainingData['target'] == 0]['instrumentalness']\n",
    "pos_popularity = trainingData[trainingData['target'] == 1]['trackPopularity']\n",
    "neg_popularity = trainingData[trainingData['target'] == 0]['trackPopularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos_popularity)\n",
    "print(neg_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.title(\"Song Tempo Like / Dislike Distribution\")\n",
    "pos_tempo.hist(alpha=0.7, bins=30, label='positive')\n",
    "neg_tempo.hist(alpha=0.7, bins=30, label='negative')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(15,15))\n",
    "\n",
    "#Danceability\n",
    "ax3 = fig2.add_subplot(331)\n",
    "ax3.set_xlabel('Danceability')\n",
    "ax3.set_ylabel('Songs')\n",
    "ax3.set_title('Danceability Distribution')\n",
    "pos_dance.hist(alpha= 0.7, bins=50, color='0.75')\n",
    "ax4 = fig2.add_subplot(331)\n",
    "neg_dance.hist(alpha= 0.3, bins=50, color='r')\n",
    "\n",
    "#Duration_ms\n",
    "ax5 = fig2.add_subplot(332)\n",
    "ax5.set_xlabel('Duration')\n",
    "ax5.set_ylabel('Songs')\n",
    "ax5.set_title('Duration Distribution')\n",
    "pos_duration.hist(alpha= 0.7, bins=50, color='0.75')\n",
    "ax6 = fig2.add_subplot(332)\n",
    "neg_duration.hist(alpha= 0.3, bins=50, color='r')\n",
    "\n",
    "#Loudness\n",
    "ax7 = fig2.add_subplot(333)\n",
    "ax7.set_xlabel('Loudness')\n",
    "ax7.set_ylabel('Songs')\n",
    "ax7.set_title('Loudness Distribution')\n",
    "pos_loudness.hist(alpha= 0.7, bins=50, color='0.75')\n",
    "ax8 = fig2.add_subplot(333)\n",
    "neg_loudness.hist(alpha= 0.3, bins=50, color='r')\n",
    "\n",
    "#Key\n",
    "ax9 = fig2.add_subplot(334)\n",
    "ax9.set_xlabel('Key')\n",
    "ax9.set_ylabel('Songs')\n",
    "ax9.set_title('Key Distribution')\n",
    "pos_key.hist(alpha= 0.7, bins=50, color='0.75')\n",
    "ax10 = fig2.add_subplot(334)\n",
    "neg_key.hist(alpha= 0.3, bins=50, color='r')\n",
    "\n",
    "#Valence\n",
    "ax11 = fig2.add_subplot(335)\n",
    "ax11.set_xlabel('Valence')\n",
    "ax11.set_ylabel('Songs')\n",
    "ax11.set_title('Valence Distribution')\n",
    "pos_valence.hist(alpha= 0.7, bins=50, color='0.75')\n",
    "ax12 = fig2.add_subplot(335)\n",
    "neg_valence.hist(alpha= 0.3, bins=50, color='r')\n",
    "\n",
    "#Energy\n",
    "ax13 = fig2.add_subplot(336)\n",
    "ax13.set_xlabel('Energy')\n",
    "ax13.set_ylabel('Songs')\n",
    "ax13.set_title('Energy Distribution')\n",
    "pos_energy.hist(alpha= 0.7, bins=50, color='0.75')\n",
    "ax14 = fig2.add_subplot(336)\n",
    "neg_energy.hist(alpha= 0.3, bins=50, color='r')\n",
    "\n",
    "#Speechiness\n",
    "ax15 = fig2.add_subplot(337)\n",
    "ax15.set_xlabel('Speechiness')\n",
    "ax15.set_ylabel('Songs')\n",
    "ax15.set_title('Speechiness Distribution')\n",
    "pos_speechiness.hist(alpha= 0.7, bins=50, color='0.75')\n",
    "ax16 = fig2.add_subplot(337)\n",
    "neg_speechiness.hist(alpha= 0.3, bins=50, color='r')\n",
    "\n",
    "#Popularity\n",
    "ax15 = fig2.add_subplot(338)\n",
    "ax15.set_xlabel('Popularity')\n",
    "ax15.set_ylabel('Songs')\n",
    "ax15.set_title('Popularity Distribution')\n",
    "pos_popularity.hist(alpha= 0.7, bins=50, color='0.75')\n",
    "ax16 = fig2.add_subplot(338)\n",
    "neg_popularity.hist(alpha= 0.3, bins=50, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"legend\", fontsize=35)\n",
    "#sns.jointplot(y=df['ENERGY'], x=df['LOUD'], kind=\"hex\", color=\"r\", size=13).set_axis_labels(\"Loudness\", \"Energy\", fontsize=35)\n",
    "#sns.jointplot(y=df['ENERGY'], x=df['ACOUSTIC'], kind=\"hex\", color=\"r\", size=13).set_axis_labels(\"Acousticness\", \"Energy\", fontsize=35)\n",
    "#sns.jointplot(y=df['DANCE'], x=df['VALENCE'], kind=\"hex\", color=\"r\", size=13).set_axis_labels(\"Valence (positive mood)\", \"Danceability\", fontsize=35)\n",
    "#sns.jointplot(y=df['ACOUSTIC'], x=df['LOUD'], kind=\"hex\", color=\"r\", size=13).set_axis_labels(\"Loudness\", \"Acousticness\", fontsize=35)\n",
    "#sns.jointplot(y=df['ENERGY'], x=df['VALENCE'], kind=\"hex\", color=\"r\", size=13).set_axis_labels(\"Valence (positive mood)\", \"Energy\", fontsize=35)\n",
    "#sns.jointplot(y=df['POP.'], x=df['ENERGY'], kind=\"hex\", color=\"r\", size=13).set_axis_labels(\"Energy\", \"Popularity\", fontsize=35)\n",
    "sns.jointplot(y=trainingData['acousticness'], x=trainingData['danceability'], kind=\"hex\", color=\"b\", size=13).set_axis_labels(\"Dance\", \"Acoustic\", fontsize=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wewh, now that we have graphs galore, lets actually get into some different classifiers and see how they preform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the set of features that we want to look at\n",
    "features = [\"danceability\", \"loudness\", \"valence\", \"energy\", \"instrumentalness\", \"acousticness\", \"key\", \"speechiness\",\"duration_ms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into x and y test and train sets to feed them into a bunch of classifiers!\n",
    "x_train = train[features]\n",
    "y_train = train[\"target\"]\n",
    "\n",
    "x_test = test[features]\n",
    "y_test = test[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) A Decision Tree Classifier\n",
    "- A decision tree classifier is often the easiest to visualize, so we will start with it first\n",
    "- All it is is pretty much a decision tree based off the features so you can trace the path down and visually see how it makes decisions. This is nice to visualize but it isn't all that good at predicting this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = DecisionTreeClassifier(min_samples_split=100)\n",
    "dt = c.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tree(InputTree, features, path):\n",
    "    f = io.StringIO()\n",
    "    tree.export_graphviz(InputTree, out_file=f, feature_names=features)\n",
    "    pydotplus.graph_from_dot_data(f.getvalue()).write_png(path)\n",
    "    img = misc.imread(path)\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "    plt.imshow(img)\n",
    "show_tree(dt, features, \"dec_tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we will see how our different classifiers do, by predicting the results on the test data and then figuring out how well they did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = c.predict(x_test)\n",
    "score = accuracy_score(y_test, y_pred) * 100\n",
    "print(\"Accuracy using Decision Tree: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree precision\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree recall\n",
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['good', 'bad']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred, labels=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Bunch More Classifier Models\n",
    "- There are some of these that take a bunch of time to finish, I wouldnt recommend running all them unless you are really intrested in the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ones that take less time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(3)\n",
    "knn_fit = knn.fit(x_train, y_train)\n",
    "knn_pred = knn.predict(x_test)\n",
    "acc = accuracy_score(y_test, knn_pred) * 100\n",
    "prec = precision_score(y_test, knn_pred) * 100\n",
    "recall = recall_score(y_test, knn_pred) * 100\n",
    "conf = confusion_matrix(y_test, knn_pred, labels=[1,0])\n",
    "print(\"Accuracy using Knn Tree: \", round(acc, 1), \"%\")\n",
    "print(\"Precision score Knn Tree:\", round(prec, 1))\n",
    "print(\"Recall score Knn Tree:\", round(recall, 1), \"%\")\n",
    "print(\"Confusion Matrix score:\\n\", conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(x_train, y_train)\n",
    "mlp_pred = mlp.predict(x_test)\n",
    "score = accuracy_score(y_test, mlp_pred) * 100\n",
    "prec = precision_score(y_test, mlp_pred) * 100\n",
    "recall = recall_score(y_test, mlp_pred) * 100\n",
    "print(\"Accuracy using MLP Tree: \", round(score, 1), \"%\")\n",
    "print(\"Precision Score using MLP Tree: \", round(prec, 1), \"%\")\n",
    "print(\"Recall Score using MLP Tree: \", round(recall, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "forest.fit(x_train, y_train)\n",
    "forest_pred = forest.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, forest_pred) * 100\n",
    "prec = precision_score(y_test, forest_pred) * 100\n",
    "recall = recall_score(y_test, forest_pred) * 100\n",
    "print(\"Accuracy using random forest: \", round(score, 1), \"%\")\n",
    "print(\"Precision Score using random forest: \", round(prec, 1), \"%\")\n",
    "print(\"Recall Score using random forest: \", round(recall, 1), \"%\")\n",
    "target_names = ['good', 'bad']\n",
    "print(classification_report(y_test, forest_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(x_train, y_train)\n",
    "ada_pred = ada.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, ada_pred) * 100\n",
    "prec = precision_score(y_test, ada_pred) * 100\n",
    "recall = recall_score(y_test, ada_pred) * 100\n",
    "print(\"Accuracy using ada: \", round(score, 1), \"%\")\n",
    "print(\"Preciscion Score using ada: \", round(prec, 1), \"%\")\n",
    "print(\"Recall Score using ada: \", round(recall, 1), \"%\")\n",
    "target_names = ['good', 'bad']\n",
    "print(classification_report(y_test, ada_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gauss = GaussianNB()\n",
    "gauss.fit(x_train, y_train)\n",
    "gauss_pred = gauss.predict(x_test)\n",
    "score = accuracy_score(y_test, gauss_pred)*100\n",
    "prec = precision_score(y_test, gauss_pred)*100\n",
    "recall = recall_score(y_test, gauss_pred)*100\n",
    "print(\"Accuracy using gauss: \", round(score, 1), \"%\")\n",
    "print(\"Accuracy using gauss: \", round(prec, 1), \"%\")\n",
    "print(\"Accuracy using gauss: \", round(recall, 1), \"%\")\n",
    "target_names = ['good', 'bad']\n",
    "print(classification_report(y_test, gauss_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=3, random_state=0)\n",
    "k_means.fit(x_train, y_train)\n",
    "predicted= k_means.predict(x_test)\n",
    "score = accuracy_score(y_test, predicted)*100\n",
    "print(\"Accuracy using Kmeans: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=.1, max_depth=1, random_state=0)\n",
    "gbc.fit(x_train, y_train)\n",
    "predicted = gbc.predict(x_test)\n",
    "score = accuracy_score(y_test, predicted)*100\n",
    "prec = precision_score(y_test, predicted)*100\n",
    "recall = recall_score(y_test, predicted)*100\n",
    "print(\"Accuracy using Gbc: \", round(score, 1), \"%\")\n",
    "print(\"Precision using Gbc: \", round(prec, 1), \"%\")\n",
    "print(\"Recall using Gbc: \", round(recall, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bc = BaggingClassifier()\n",
    "bc.fit(x_train, y_train)\n",
    "predicted = bc.predict(x_test)\n",
    "score = accuracy_score(y_test, predicted)*100\n",
    "prec = precision_score(y_test, predicted)*100\n",
    "recall = recall_score(y_test, predicted)*100\n",
    "print(\"Accuracy using bc: \", round(score, 1), \"%\")\n",
    "print(\"Precision using bc: \", round(prec, 1), \"%\")\n",
    "print(\"Recall using bc: \", round(recall, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf1 = GradientBoostingClassifier(learning_rate=0.2, max_depth=10, n_estimators=300)\n",
    "clf2 = BaggingClassifier(n_estimators=100)\n",
    "# lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2]\n",
    "                          , meta_classifier=clf1\n",
    "                          , use_probas=True\n",
    "                          , average_probas=False,)\n",
    "\n",
    "print('3-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, sclf], \n",
    "                      ['GBC', \n",
    "                       'BC',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = cross_val_score(clf, x_train, y_train, \n",
    "                                              cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ones that take more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(x_train, y_train)\n",
    "qda_pred = qda.predict(x_test)\n",
    "score = accuracy_score(y_test, qda_pred)*100\n",
    "print(\"Accuracy using qda: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_lin = SVC(kernel=\"linear\", C=0.025)\n",
    "svc_lin.fit(x_train, y_train)\n",
    "svc_pred = svc_lin.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, svc_pred) * 100\n",
    "print(\"Accuracy using svc linear: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "gpc = GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True)\n",
    "gpc.fit(x_train, y_train)\n",
    "gpc_pred = gpc.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, gpc_pred) * 100\n",
    "print(\"Accuracy using gpc: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we should have a classifier with the highest accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to pick a playlist you want you classifier to find songs you like in...\n",
    "- Use the same thing you used to find the good and bad playlists to specify this new playlist you've taken an intrest in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "playlistToFindSongsYouLikeIn = sp.user_playlist(\"spotify\", \"37i9dQZEVXcFqDuJHHirGk\")\n",
    "\n",
    "newPlaylist_tracks = playlistToFindSongsYouLikeIn[\"tracks\"]\n",
    "newPlaylist_songs = newPlaylist_tracks[\"items\"] \n",
    "while newPlaylist_tracks['next']:\n",
    "    newPlaylist_tracks = sp.next(newPlaylist_tracks)\n",
    "    for song in newPlaylist_tracks[\"items\"]:\n",
    "        newPlaylist_songs.append(song)\n",
    "        \n",
    "newPlaylist_song_ids = [] \n",
    "print(len(newPlaylist_songs))\n",
    "for i in range(len(newPlaylist_songs)):\n",
    "    newPlaylist_song_ids.append(newPlaylist_songs[i]['track']['id'])\n",
    "    \n",
    "newPlaylist_features = []\n",
    "j = 0\n",
    "for i in range(0,len(newPlaylist_song_ids),50):\n",
    "    audio_features = sp.audio_features(newPlaylist_song_ids[i:i+50])\n",
    "    for track in audio_features:\n",
    "        track['song_title'] = newPlaylist_songs[j]['track']['name']\n",
    "        track['artist'] = newPlaylist_songs[j]['track']['artists'][0]['name']\n",
    "        j= j + 1\n",
    "        newPlaylist_features.append(track)\n",
    "print(len(newPlaylist_features))\n",
    "\n",
    "playlistToLookAtFeatures = pd.DataFrame(newPlaylist_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We just loaded in your new tracks and audio features for those tracks\n",
    "- Now all we have to do is find the highest accuracy value out of all you classifiers (for me it was gdc) and predict what we will have over the new playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick aside: you can put these into a new playlist as well, just use the sp.user_playlist_add_tracks function\n",
    "- The function looks like this user_playlist_add_tracks(\"username\", \"playlist_id\", \"track_id_to_add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = gbc.predict(playlistToLookAtFeatures[features])\n",
    "\n",
    "likedSongs = 0\n",
    "i = 0\n",
    "for prediction in pred:\n",
    "    if(prediction == 1):\n",
    "        print (\"Song: \" + playlistToLookAtFeatures[\"song_title\"][i] + \", By: \"+ playlistToLookAtFeatures[\"artist\"][i])\n",
    "        #sp.user_playlist_add_tracks(\"1287242681\", \"7eIX1zvtpZR3M3rYFVA7DF\", [test['id'][i]])\n",
    "        likedSongs= likedSongs + 1\n",
    "    i = i +1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There Ya Go!\n",
    "- This was my quick overview of my process of how I used classifiers and spoitfy to try and help me find tracks I might like in any playlist on spotify!\n",
    "- I want to make this tutorial less involved and figure out a way to make my classifiers better as well as using Tensorflow to make a model in order to do this for me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline([(\"imputer\", SimpleImputer(strategy='mean'))\n",
    "                      , ('standardizer', StandardScaler())\n",
    "                      , (\"gbm\", GradientBoostingClassifier())\n",
    "                     ])\n",
    "\n",
    "parameters = {'gbm__n_estimators': [50, 100, 300]\n",
    "              , 'gbm__max_depth' : [8, 10, 12]\n",
    "              , 'gbm__learning_rate' : [0.1, 0.2, 0.7]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator, parameters, cv=3, verbose=3, scoring='roc_auc', n_jobs=1)\n",
    "gs.fit(x_train, y_train.values.ravel())\n",
    "gs.best_params_\n",
    "\n",
    "tuned_estimator = Pipeline([(\"imputer\", SimpleImputer(strategy='mean'))\n",
    "                      , ('standardizer', StandardScaler())\n",
    "                      , (\"gbm\", GradientBoostingClassifier(learning_rate=0.2\n",
    "                                                          , max_depth=10\n",
    "                                                          , n_estimators=300))\n",
    "                     ])\n",
    "\n",
    "tuned_estimator.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "predicted = tuned_estimator.predict(x_test)\n",
    "score = accuracy_score(y_test, predicted)*100\n",
    "print(\"Accuracy using Tuned GBC: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline([(\"imputer\", SimpleImputer(strategy='mean'))\n",
    "                      , ('standardizer', StandardScaler())\n",
    "                      , (\"bc\", BaggingClassifier())\n",
    "                     ])\n",
    "\n",
    "parameters = {'bc__n_estimators': [50, 100, 300]}\n",
    "\n",
    "gs = GridSearchCV(estimator, parameters, cv=3, verbose=3, scoring='roc_auc', n_jobs=1)\n",
    "gs.fit(x_train, y_train.values.ravel())\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_estimator = Pipeline([(\"imputer\", SimpleImputer(strategy='mean'))\n",
    "                      , ('standardizer', StandardScaler())\n",
    "                      , (\"bc\", BaggingClassifier(n_estimators=100))\n",
    "                     ])\n",
    "\n",
    "tuned_estimator.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "\n",
    "predicted = tuned_estimator.predict(x_test)\n",
    "score = accuracy_score(y_test, predicted)*100\n",
    "print(\"Accuracy using Tuned BC: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
